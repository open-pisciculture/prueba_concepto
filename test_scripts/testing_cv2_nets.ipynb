{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('capturedIMG.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_net = cv2.dnn.readNet(\"models/yolov4-tiny-detector_best_pisciculturedb.weights\", \"models/yolov4-tiny_testing_3chan.cfg\")\n",
    "\n",
    "caffe_net = cv2.dnn.readNetFromCaffe(\"models/MobileNetSSD_deploy.prototxt\", \"models/MobileNetSSD_deploy.caffemodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_layer_names = yolo_net.getLayerNames()\n",
    "yolo_output_layers = [yolo_layer_names[i[0] - 1] for i in yolo_net.getUnconnectedOutLayers()]\n",
    "\n",
    "# caffe_layer_names = yolo_net.getLayerNames()\n",
    "# caffe_output_layers = [caffe_layer_names[i[0] - 1] for i in caffe_net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width, channels = img.shape # Yolo\n",
    "(H, W) = img.shape[:2]              # Caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "caffe_blob = cv2.dnn.blobFromImage(img, 0.007843, (W, H), 127.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolo_blob.shape: (1, 3, 416, 416)\n",
      "caffe_blob.shape: (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "print(f\"yolo_blob.shape: {yolo_blob.shape}\")\n",
    "print(f\"caffe_blob.shape: {caffe_blob.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_net.setInput(yolo_blob)\n",
    "yolo_outs = yolo_net.forward(yolo_output_layers)\n",
    "\n",
    "caffe_net.setInput(caffe_blob)\n",
    "caffe_detections = caffe_net.forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yolo Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing informations on the screen\n",
    "class_ids = []\n",
    "confidences = []\n",
    "boxes = []\n",
    "for out in yolo_outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.0:\n",
    "            # Object detected\n",
    "            center_x = int(detection[0] * width)\n",
    "            center_y = int(detection[1] * height)\n",
    "            w = int(detection[2] * width)\n",
    "            h = int(detection[3] * height)\n",
    "\n",
    "            # Rectangle coordinates\n",
    "            x = int(center_x - w / 2)\n",
    "            y = int(center_y - h / 2)\n",
    "\n",
    "            boxes.append([x, y, w, h])\n",
    "            confidences.append(float(confidence))\n",
    "            class_ids.append(class_id)\n",
    "num_peces = 0\n",
    "\n",
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "for i in range(len(boxes)):\n",
    "    if i in indexes:\n",
    "        num_peces += 1\n",
    "        x, y, w, h = boxes[i]\n",
    "        label = str(classes[class_ids[i]])\n",
    "        color = colors[class_ids[i]]\n",
    "        cv2.rectangle(color_img, (x, y), (x + w, y + h), color, 2)\n",
    "        cv2.putText(color_img, label, (x, y + 30), font, 2, color, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[317, 232, 89, 75]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caffe Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "           \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "           \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "           \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "# loop over the detections\n",
    "for i in np.arange(0, caffe_detections.shape[2]):\n",
    "    # extract the confidence (i.e., probability) associated\n",
    "    # with the prediction\n",
    "    confidence = caffe_detections[0, 0, i, 2]\n",
    "\n",
    "    # filter out weak detections by requiring a minimum\n",
    "    # confidence\n",
    "    if confidence > 0.5:\n",
    "        # extract the index of the class label from the\n",
    "        # detections list\n",
    "        idx = int(caffe_detections[0, 0, i, 1])\n",
    "\n",
    "        # if the class label is not a person, ignore it\n",
    "        if CLASSES[idx] != \"person\":\n",
    "            continue\n",
    "\n",
    "        # compute the (x, y)-coordinates of the bounding box\n",
    "        # for the object\n",
    "        box = caffe_detections[0, 0, i, 3:7] * np.array([W, H, W, H])\n",
    "        (startX, startY, endX, endY) = box.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([300.26351929, 153.65833282, 583.85047913, 446.86712265])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b3ded1ccb95c1d9bd405e7b823d9e85424cde40fbb5985eb47e999ef50e15b4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
